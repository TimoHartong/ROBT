#ifndef GPLFIX_H
#define GPLFIX_H

#include <stdlib.h>

#include "linux/errno.h"
#include "gpl/include/net/dropreason.h"




// Make sure all the lib is compiled swithes skbuff.h
#define CONFIG_BT_FEATURE_DEBUG             1
#define __KERNEL__                          1
#define CONFIG_NF_CONNTRACK                 0
#define CONFIG_NETFILTER_XT_TARGET_TRACE    0
#define CONFIG_NF_TABLES                    0
#define CONFIG_IP_VS                        0
#define BITS_PER_LONG                       0

// switches hci_core
#define CONFIG_BT_BREDR                     0
#define CONFIG_BT_LE                        1

// switched in hci_defugfs
#define CONFIG_BT_DEBUGFS                   0

// switches in net/bluetooth/smp.h
#define CONFIG_BT_SELFTEST_SMP              0

/*include/linux/bitops.h */
#define BIT(nr)    (1UL << (nr))


#define MSG_DONTWAIT 0x80;
// gfp.h
#define __GFP_WAIT          0x10
#define __GFP_IO            0x40
#define __GFP_FS            0x80
#define GFP_KERNEL (__GFP_WAIT | __GFP_IO | __GFP_FS)
#define GFP_ATOMIC         0x02

// asm-generic/errno-base.h
#define EOPNOTSUPP           95
#define ENODEV               19
#define EPERM                1
#define EBUSY                16
#define ENOSPC               28  /* No space on device */
#define ERFKILL              132
// include/nolibc/errno.h

#define MAX_ERRNO            4095
#define EINTR                4
#define ENOMEM               12
#define EINVAL               22
//#define EINVAL               4
#define ERESTARTSYS          512   // linux/errno.h

/* include/uapi/asm/errno.h */
#define ECANCELED          125

#define MSEC_PER_SEC       1000
typedef int atomic_t;

// Google popped up this but header location is unknown
#define IS_ENABLED(m)       ( (m) != 0 )

// include/linux/err.h
#define IS_ERR_VALUE(x)     (unsigned long)(void *)(x) >= (unsigned long) -MAX_ERRNO)

/* include/linux/numa.h */
#define NUMA_NO_NODE (-1)
/* include/acpi/platvorm/acenv.h */
typedef char *va_list;

/* include/linux/printk.h */
struct va_format {
  const char *fmt;
  va_list *va;
};

static inline bool IS_ERR(const void *ptr)
{
//   return IS_ERR_VALUE((unsigned long)ptr);
return false;
}

static inline bool IS_ERROR(const void *ptr)
{
  return 0;
}

static inline bool PTR_ERR(const void *ptr)
{
  return 0;
}

/**
 * ERR_PTR - Create an error pointer.
 * @error: A negative error code.
 *
 * Encodes @error into a pointer value. Users should consider the result
 * opaque and not assume anything about how the error is encoded.
 *
 * Return: A pointer with @error encoded within its value.
 */
 // static inline void * __must_check ERR_PTR(long error)
static inline void *ERR_PTR(long error)
{
	return (void *) error;
}

/* include/linux/gfp_types.h */
typedef unsigned int gfp_t;

/* Just a dummy certainly not meant for actual implementation */
//struct sk_buff {
//  struct sk_buff   *next, *prev;
//  uint8_t          *head;  // Buffer start
//  uint8_t          *data;  // Data start
//  uint8_t          *tail;  // Data end
//  uint8_t          *end;  // Buffer end
//  uint32_t         len;   // Data length
//  uint32_t         data_len; // Length of the paged data
//};

//struct sk_buff_head {
//  struct sk_buff *next;
//  struct sk_buff *pref;
//};

//static inline void skb_reserve(struct sk_buff *skb, int len);
//struct sk_buff *alloc_skb(unsigned int size, gfp_t priority);
//struct sk_buff *skb_get(struct sk_buff *skb);
//unsigned char *skb_put(struct sk_buff *skb, unsigned int len);
//void *skb_put_data(struct sk_buff *skb, const void *data, unsigned int len);
//int skb_queue_empty(const struct sk_buff_head *list);
//void skb_queue_tail(struct sk_buff_head *list, struct sk_buff *newsk);
//__u32 skb_queue_len(struct sk_buff_head *list_);
//void skb_queue_purge(struct sk_buff_head *list);
//struct sk_buff *skb_peek_tail( struct sk_buff_head *list_ );
//void skb_queue_head_init( struct sk_buff_head *list );
//void skb_queue_splice_tail(struct sk_buff_head *list , struct sk_buff_head *head);

//static inline void skb_reserve(struct sk_buff *skb, int len)
//{
//  skb->data += len;
//  skb->tail += len;
//}

// linux/include/linux/firmware.h
struct firmware {
  size_t     size;
  const u8   *data;
  void       *priv;
};

int firmware_request_nowarn(const struct firmware **fw, const char *name, struct device *device);

void release_firmware(const struct firmware *fw);

// mod_devicetable.h Only limit taken over
#define DMI_MATCH(a, b) { a , b }

enum dmi_field {
  DMI_NONE,
  DMI_BOARD_VENDOR,
  DMI_PRODUCT_NAME
};

struct dmi_strmatch {
  unsigned char slot;
  char          substr[79];
};

struct dmi_system_id {
  const char          *ident;
  struct dmi_strmatch matches[4];
  void                *driverdata;

};

/* from include/linux/dmi.h */
static inline const struct dmi_system_id* dmi_first_match(const struct dmi_system_id *list) { return NULL; }

/*Unknown where defined*/
//void set_bit(u32 nr, volatile u32 *addr);
u16 le16_to_cpu(u16 value); // Pi ARM alread little endian
int snprintf(char *buff, size_t buff_size, const char *format, ... );
void kvfree(const void* addr);
u16 cpu_to_le16(u16 value);
void atomic_set(atomic_t *v, int i);
#define EIO   5


/* sys/malloc.h */
void *kmalloc(size_t size, gfp_t flags);
void *kfree(void *addr);


/* include/asm-generic/unaligment.h */
static inline u16 get_unaligned_le16(const void *p)
{
  return 0;
}

/*  include/linux/device.h */
struct device {
  struct device		*parent;
  const u8              *init_name;
  u32                   id;
  void	                *driver_data;
};

extern struct device *get_device(struct device *dev);
extern void put_device(struct device *dev);

static inline void *dev_get_drvdata(const struct device *dev)
{
	return dev->driver_data;
}

static inline void dev_set_drvdata(struct device *dev, void *data)
{
	dev->driver_data = data;
}

/* include/linux/types.h */
struct list_head {
  struct list_head *next;
  struct list_head *prev;
};

/* incluide/linux/rcuupdate.h */
struct rcu_head {
  struct rcu_head *next;
  void (*func)(struct rcu_head *head);
};

void rcu_read_lock(void);
void rcu_read_unlock(void);

/* include/linux/rculist.h */
void list_add_tail_rcu( struct list_head *new , struct list_head *head );

/**
 * list_first_entry_rcu - get the first element from a list
 * @ptr:        the list head to take the element from.
 * @type:       the type of the struct this is embedded in.
 * @member:     the name of the list_struct within the struct.
 *
 * Note, that list is expected to be not empty.
 *
 * This primitive may safely run concurrently with the _rcu list-mutation
 * primitives such as list_add_rcu() as long as it's guarded by rcu_read_lock().
 */
#define list_first_entry_rcu(ptr, type, member) \
	({})

/**
 * list_del_rcu - deletes entry from list without re-initialization
 * @entry: the element to delete from the list.
 *
 * Note: list_empty() on entry does not return true after this,
 * the entry is in an undefined state. It is useful for RCU based
 * lockfree traversal.
 *
 * In particular, it means that we can not poison the forward
 * pointers that may still be used for walking the list.
 *
 * The caller must take whatever precautions are necessary
 * (such as holding appropriate locks) to avoid racing
 * with another list-mutation primitive, such as list_del_rcu()
 * or list_add_rcu(), running on this same list.
 * However, it is perfectly legal to run concurrently with
 * the _rcu list-traversal primitives, such as
 * list_for_each_entry_rcu().
 *
 * Note that the caller is not permitted to immediately free
 * the newly deleted entry.  Instead, either synchronize_rcu()
 * or call_rcu() must be used to defer freeing until an RCU
 * grace period has elapsed.
 */
void list_del_rcu(struct list_head *entry);
//{
//	__list_del(entry->prev, entry->next);
//	entry->prev = LIST_POISON2;
//}

/* rcuupdate.h */
extern void synchronize_rcu(void);



/*  include/linux/workquque.h */

struct work_struct {
  struct list_head entry;  // FIXME missing items
};

struct delayed_work {
  struct work_struct work;  // Missing members
};

/* from workquee.c taken out a lot of members */
struct workqueue_struct {
	struct list_head	pwqs;		/* WR: all pwqs of this wq */
	struct list_head	list;		/* PR: list of all workqueues */
};

extern bool cancel_delayed_work(struct delayed_work *dwork);
extern bool cancel_delayed_work_sync(struct delayed_work *dwork);
extern bool cancel_work_sync(struct work_struct *work);
extern bool flush_work(struct work_struct *work);
extern void drain_workqueue(struct workqueue_struct *wq);
extern bool flush_delayed_work(struct delayed_work *dwork);

extern bool queue_delayed_work_on(int cpu, struct workqueue_struct *wq,
			struct delayed_work *work, unsigned long delay);

bool queue_work( struct workqueue_struct *wq , struct work_struct *work );
extern bool disable_delayed_work(struct delayed_work *dwork);
// To be implemented as empty funtion ? */
//#define queue_work(wq, work){}

/**
 * queue_delayed_work - queue work on a workqueue after delay
 * @wq: workqueue to use
 * @dwork: delayable work to queue
 * @delay: number of jiffies to wait before queueing
 *
 * Equivalent to queue_delayed_work_on() but tries to use the local CPU.
 */
static inline bool queue_delayed_work(struct workqueue_struct *wq,
				      struct delayed_work *dwork,
				      unsigned long delay)
{
	return queue_delayed_work_on(1, wq, dwork, delay);
}


/* include/linux/skbuff.h */
//struct sk_buff_head {
//  struct sk_buff *next;
//  struct sk_buff *prev;
//};



/* include/linux/srcu.h */
struct srcu_struct {
  unsigned long c[2];
  unsigned long seq[2];
};

/* include/linux/idr.h */
struct idr_layer {
  unsigned long    bitmap;
  struct idr_layer *ary;
  int              count;
  int              layer;
  struct rcu_head  rcu_head;
};

struct idr {
  struct idr_layer *top;
  struct idr_layer *id_free;
  int              layers;
  int              id_free_cnt;
};

/* include/linux/idr.h */

bool idr_is_empty(const struct idr *idr);

#define IDA_CHUNK_SIZE      128
#define IDA_BITMAP_LONGS    (IDA_CHUNK_SIZE / sizeof(long) - 1)

struct ida_bitmap {
  long nr_busy;
  unsigned long bitmap[IDA_BITMAP_LONGS];
};

struct ida {
  struct idr        idr;
  struct ida_bitmap *free_bitmap;
};

/* /include/linux/mutex.h */
struct mutex {
  struct list_head wait_list;   // members missing
  const char *name;
  void       *magic;
};

void mutex_lock(struct mutex *lock);
void mutex_unlock(struct mutex *lock);

/**
 * mutex_init - initialize the mutex
 * @mutex: the mutex to be initialized
 *
 * Initialize the mutex to unlocked state.
 *
 * It is not allowed to initialize an already locked mutex.
 */
void mutex_init(struct mutex *lock);


/* include/linux/notifier.h */
struct notifier_block {
  int (*notifier_call)(struct notifier_block *, unsigned long , void *);
  struct notifier_block *next;
  int priority;
};

/* linux/list.h */

static inline void INIT_LIST_HEAD(struct list_head *list)
{
  //WRITE_ONCE(list->next, list);
  list->next = list ;
  //WRITE_ONCE(list->prev, list);
  list->prev = list ;
}

static inline void __list_add(struct list_head *new,
			      struct list_head *prev,
			      struct list_head *next)
{
	next->prev = new;
	new->next = next;
	new->prev = prev;
	prev->next = new;
}

static inline void __list_del(struct list_head * prev, struct list_head * next)
{
	next->prev = prev;
	prev->next = next;
}


static inline void list_del(struct list_head *entry)
{
	__list_del(entry->prev, entry->next);
	entry->next = NULL;
	entry->prev = NULL;
}

/**
 * list_empty - tests whether a list is empty
 * @head: the list to test.
 */
static inline int list_empty(const struct list_head *head)
{
	return head->next == head;
}

/**
 * list_first_entry_or_null - get the first element from a list
 * @ptr:	the list head to take the element from.
 * @type:	the type of the struct this is embedded in.
 * @member:	the name of the list_head within the struct.
 *
 * Note that if the list is empty, it returns NULL.
 */
#define list_first_entry_or_null(ptr, type, member) ({ })

/**
 * list_add_tail - add a new entry
 * @new: new entry to be added
 * @head: list head to add it before
 *
 * Insert a new entry before the specified head.
 * This is useful for implementing queues.
 */
static inline void list_add_tail(struct list_head *new, struct list_head *head)
{
	__list_add(new, head->prev, head);
}

/**
 * list_entry - get the struct for this entry
 * @ptr:	the &struct list_head pointer.
 * @type:	the type of the struct this is embedded in.
 * @member:	the name of the list_struct within the struct.
 */
//#define list_entry(ptr, type, member) \
	container_of(ptr, type, member)

/**
 * list_for_each_entry	-	iterate over list of given type
 * @pos:	the type * to use as a loop cursor.
 * @head:	the head for your list.
 * @member:	the name of the list_struct within the struct.
 */
//#define arraylen(arr) (sizeof(arr)/sizeof(arr[0]))
//#define foreach(idxtype, idxpvar, col, colsiz)
//idxtype* idxpvar;
//for (idxpvar = col; idxpvar < (col + colsiz); ++idxpvar)

//#define foreach(idxtype, idxpvar, col ) \
idxtype* idxpvar; \
for( idxpvar = col; idxpvar != NULL ; idxpvar = idxpvar->next)



/* include/linux/spinlock.h */
void spin_lock_init(void);
void spin_lock(void);
void spin_unlock(void);

/* include/asm/bitops.h */
bool test_bit(u32 nr, u32 addr);
void clear_bit(u32 nr, u32 addr);
void set_bit(u32 nr, u32 addr);
void change_bit(u32 nr, u32 addr);
bool test_and_set_bit(u32 nr, u32 addr);
bool test_and_clear_bit(u32 nr, u32 addr);
bool test_and_change_bit(u32 nr, u32 addr);

/* include/linux/time.h */
typedef u32 ktime_t;  // Very free conversion ;-)

/* include/net/sock.h */
void sock_put(void* sock);
void sock_hold(void* sock);

void wake_up_interruptible(__u32 *request);

/*include/linux/overflow.h */
#define structsize(p,member,count)  { return 0;}

/**
 * struct_size() - Calculate size of structure with trailing flexible array.
 * @p: Pointer to the structure.
 * @member: Name of the array member.
 * @count: Number of elements in the array.
 *
 * Calculates size of memory needed for structure of @p followed by an
 * array of @count number of @member elements.
 *
 * Return: number of bytes needed or SIZE_MAX on overflow.
 */




/* include/linux/spinlock.h */
// Empty function and that is no issue they are supposed to do noting at all
#define spin_lock_irqsave(lock, flags) {}
#define spin_unlock_irqrestore(lock, flags) {}

/* include/linux/jiffries.h */
unsigned long msecs_to_jiffies(const unsigned int m);

#define INIT_WORK(_work, _func)	 {}
#define INIT_DELAYED_WORK(_work, _func)	{}

/* uapi/linux/random.h  */
void get_random_bytes(void* buf, int nbytes);

/* include/linux/mm.h  */
void *kvcalloc(size_t n, size_t size, gfp_t flags);

/* include/linux/fwnode.h */
struct fwnode_handle {
	struct fwnode_handle *secondary;
//	const struct fwnode_operations *ops;

	/* The below is used solely by device links, don't use otherwise */
	struct device *dev;
	struct list_head suppliers;
	struct list_head consumers;
	u8 flags;
};

/* include/linux/property.h */
struct fwnode_handle *dev_fwnode(struct device *dev);

/*  linux/driver/base/property.c */
int fwnode_property_read_u8_array(const struct fwnode_handle *fwnode, const char *propname, u8 *val, size_t nval);

bool fwnode_property_present(const struct device *dev, const char *propname);

/* Please note this should be compiled as an atomic op with memory barriers */
#define WRITE_ONCE(x, val)  x=(val)

/* include/linux/byteorder/little_endian.h */
#define __cpu_to_le64(x) (( __le64)(__u64)(x))
#define __le64_to_cpu(x) (( __u64)(__le64)(x))
#define __cpu_to_le32(x) (( __le32)(__u32)(x))
#define __le32_to_cpu(x) (( __u32)(__le32)(x))
#define __cpu_to_le16(x) (( __le16)(__u16)(x))
#define __le16_to_cpu(x) (( __u16)(__le16)(x))
//#define __cpu_to_be64(x) (( __be64)__swab64((x)))
//#define __be64_to_cpu(x) __swab64(( __u64)(__be64)(x))
//#define __cpu_to_be32(x) (( __be32)__swab32((x)))
//#define __be32_to_cpu(x) __swab32(( __u32)(__be32)(x))
//#define __cpu_to_be16(x) (( __be16)__swab16((x)))
//#define __be16_to_cpu(x) __swab16(( __u16)(__be16)(x))

static inline __le64 __cpu_to_le64p(const __u64 *p)
{
	return ( __le64)*p;
}
static inline __u64 __le64_to_cpup(const __le64 *p)
{
	return ( __u64)*p;
}
static inline __le32 __cpu_to_le32p(const __u32 *p)
{
	return ( __le32)*p;
}
static inline __u32 __le32_to_cpup(const __le32 *p)
{
	return ( __u32)*p;
}
static inline __le16 __cpu_to_le16p(const __u16 *p)
{
	return ( __le16)*p;
}
static inline __u16 __le16_to_cpup(const __le16 *p)
{
	return ( __u16)*p;
}
/*
static inline __be64 __cpu_to_be64p(const __u64 *p)
{
	return ( __be64)__swab64p(p);
}
static inline __u64 __be64_to_cpup(const __be64 *p)
{
	return __swab64p((__u64 *)p);
}
static inline __be32 __cpu_to_be32p(const __u32 *p)
{
	return ( __be32)__swab32p(p);
}
static inline __u32 __be32_to_cpup(const __be32 *p)
{
	return __swab32p((__u32 *)p);
}
static inline __be16 __cpu_to_be16p(const __u16 *p)
{
	return ( __be16)__swab16p(p);
}
static inline __u16 __be16_to_cpup(const __be16 *p)
{
	return __swab16p((__u16 *)p);
}
#define __cpu_to_le64s(x) do { (void)(x); } while (0)
#define __le64_to_cpus(x) do { (void)(x); } while (0)
#define __cpu_to_le32s(x) do { (void)(x); } while (0)
#define __le32_to_cpus(x) do { (void)(x); } while (0)
#define __cpu_to_le16s(x) do { (void)(x); } while (0)
#define __le16_to_cpus(x) do { (void)(x); } while (0)
#define __cpu_to_be64s(x) __swab64s((x))
#define __be64_to_cpus(x) __swab64s((x))
#define __cpu_to_be32s(x) __swab32s((x))
#define __be32_to_cpus(x) __swab32s((x))
#define __cpu_to_be16s(x) __swab16s((x))
#define __be16_to_cpus(x) __swab16s((x))
*/

/* include/linux/property.h */

/* Macros for min/max. comming from BSD sys/sys/param.h */
#define	MIN(a,b) (((a)<(b))?(a):(b))
#define	MAX(a,b) (((a)>(b))?(a):(b))

/* include/linux/array_size.h */
#define ARRAY_SIZE(arr) (sizeof(arr) / sizeof((arr)[0])

/* include/linux/types.h */
//typedef struct {
//	int counter;
//} atomic_t;

#include "linux/refcount_types.h"

/* include/linux/ktime.h */
/*
 * ktime_t:
 *
 * A single 64-bit variable is used to store the hrtimers
 * internal representation of time values in scalar nanoseconds. The
 * design plays out best on 64-bit CPUs, where most conversions are
 * NOPs and most arithmetic ktime_t operations are plain arithmetic
 * operations.
 *
 */
union ktime {
	s64	tv64;
};

/* include/linux/uio.h */

struct iov_iter {
	int type;
	size_t iov_offset;
	size_t count;
//	union {
//		const struct iovec *iov;
//		const struct kvec *kvec;
//		const struct bio_vec *bvec;
//		struct pipe_inode_info *pipe;
//	};
	union {
		unsigned long nr_segs;
		struct {
			int idx;
			int start_idx;
		};
	};
};

bool copy_from_iter_full(void *addr, size_t bytes, struct iov_iter *i);
//typedef union ktime ktime_t;		/* Kill this */

#include "linux/skbuff.h"

/* linux/net/socket.h */

struct msghdr {
	void		*msg_name;	/* ptr to socket address structure */
	int		msg_namelen;	/* size of socket address structure */

	int		msg_inq;	/* output, data left in socket */
	int             msg_flags;      // keep the compiler happy
	struct iov_iter   msg_iter;       // keep the compiler happy
};

struct sock {
  u32 crap;
  u32 sk_err;
  u32 sk_shutdown;
  u32 priority;
  u32 sk_priority;
};

struct sk_buff *sock_alloc_send_skb(struct sock *sk, unsigned long size,
				    int noblock, int *errcode);
struct sk_buff *sock_alloc_send_pskb(struct sock *sk, unsigned long header_len,
				     unsigned long data_len, int noblock,
				     int *errcode, int max_page_order);

/*
 *	Recover an error report and clear atomically
 */

static inline int sock_error(struct sock *sk)
{
	int err;
	if (!sk->sk_err)
	   return 0;

	err = sk->sk_err;

//	err = xchg(&sk->sk_err, 0);
	return -err;
}


#endif
